{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning algorithm\n",
    "\n",
    "The steps involved in a typical RL algorithm are as follows:\n",
    "\n",
    "1. First, the agent interacts with the environment by performing an action.\n",
    "2. By performing an action, the agent moves from one state to another.\n",
    "3. Then the agent will receive a reward based on the action it performed.\n",
    "4. Based on the reward, the agent will understand whether the action is good or bad.\n",
    "5. If the action was good, that is, if the agent received a positive reward, then the agent will prefer performing that action, else the agent will try performing other actions in search of a positive reward.\n",
    "\n",
    "RL is basically a trial and error learning process. Now, let's revisit our chess game\n",
    "example. The agent (software program) is the chess player. So, the agent interacts\n",
    "with the environment (chessboard) by performing an action (moves). If the agent\n",
    "gets a positive reward for an action, then it will prefer performing that action; else it\n",
    "will find a different action that gives a positive reward.\n",
    "\n",
    "Ultimately, the goal of the agent is to maximize the reward it gets. If the agent\n",
    "receives a good reward, then it means it has performed a good action. If the agent\n",
    "performs a good action, then it implies that it can win the game. Thus, the agent\n",
    "learns to win the game by maximizing the reward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
